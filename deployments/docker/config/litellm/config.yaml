# Model configuration - lists all models available through the proxy
model_list:
  # Ollama models - direct access to your local models
  - model_name: ollama/llama3
    litellm_params:
      model: ollama/llama3
      api_base: http://ollama:11434
      drop_params: true # Removes extra parameters when calling specific models

  - model_name: ollama/mxbai-embed-large
    litellm_params:
      model: ollama/mxbai-embed-large
      api_base: http://ollama:11434
      drop_params: true

  # OpenAI models - requires API key
  - model_name: openai/gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      drop_params: true

  # OpenAI embedding model
  - model_name: openai/text-embedding-3-large
    litellm_params:
      model: openai/text-embedding-3-large
      api_key: os.environ/OPENAI_API_KEY
      drop_params: true

  # Model aliases without provider prefixes for simpler referencing
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      drop_params: true
  
  - model_name: text-embedding-3-large
    litellm_params:
      model: openai/text-embedding-3-large
      api_key: os.environ/OPENAI_API_KEY
      drop_params: true

  # Gemini models - requires API key
  - model_name: gemini/gemini-1.5-pro
    litellm_params:
      model: gemini/gemini-1.5-pro
      api_key: os.environ/GEMINI_API_KEY
      rpm: 15
      tpm: 1000000
      drop_params: true

  # Gemini embedding model for RAG
  - model_name: gemini/text-embedding-004
    litellm_params:
      model: gemini/text-embedding-004
      api_key: os.environ/GEMINI_API_KEY
      rpm: 15
      tpm: 1000000
      drop_params: true
      
  # Obelisk RAG - custom implementation
  - model_name: obelisk-rag/llama3
    litellm_params:
      model: ollama/llama3 # Using ollama provider format with llama3 model
      api_base: http://obelisk-rag:8000
      api_key: dummy-key
      drop_params: true
      
  # Obelisk RAG alias without provider prefix
  - model_name: obelisk-rag
    litellm_params:
      model: ollama/llama3 # Using ollama provider format with llama3 model
      api_base: http://obelisk-rag:8000
      api_key: dummy-key
      drop_params: true

  # Obelisk RAG embeddings
  - model_name: obelisk-rag/embeddings
    litellm_params:
      model: openai/text-embedding-ada-002 # Placeholder, obelisk-rag uses its own embedding model
      api_base: http://obelisk-rag:8000
      api_key: dummy-key
      drop_params: true

# Router settings
router_settings:
  # Route embeddings to correct endpoints - prioritize OpenAI when available
  embedding_models:
    - openai/text-embedding-3-large
    - text-embedding-3-large
    - gemini/text-embedding-004
    - ollama/mxbai-embed-large
    - obelisk-rag/embeddings
  
  # Fallback configuration for model resilience
  fallbacks: [
    {
      "model": "openai/gpt-4o",
      "fallback_model": "ollama/llama3"
    },
    {
      "model": "gpt-4o", 
      "fallback_model": "ollama/llama3"
    },
    {
      "model": "openai/text-embedding-3-large", 
      "fallback_model": "ollama/mxbai-embed-large"
    },
    {
      "model": "text-embedding-3-large", 
      "fallback_model": "ollama/mxbai-embed-large"
    }
  ]
  
  # Default timeout in seconds
  timeout: 30
  # Routing strategy
  routing_strategy: simple-shuffle
  # Number of retries
  num_retries: 2

# General settings
general_settings:
  # Forward OpenAI Organization ID for enterprise customers
  forward_openai_org_id: true

# Custom endpoint settings for models that implement OpenAI API format
custom_endpoints:
  # Map from models to URL path prefixes
  obelisk-rag: 
    url: http://obelisk-rag:8000
    models:
      - obelisk-rag/llama3
      - obelisk-rag
      - obelisk-rag/embeddings

# LiteLLM specific settings
litellm_settings:
  # Enable schema validation for requests
  enable_json_schema_validation: True
  # Enable Langfuse tracing (optional)
  # langfuse_project_id: os.environ/LANGFUSE_PROJECT_ID
  # langfuse_public_key: os.environ/LANGFUSE_PUBLIC_KEY
  # langfuse_secret_key: os.environ/LANGFUSE_SECRET_KEY